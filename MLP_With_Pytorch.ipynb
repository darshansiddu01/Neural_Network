{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled0.ipynb","version":"0.3.2","provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"metadata":{"id":"pvLYiycHGGZs","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":346},"outputId":"5660e279-67ca-4bae-de2d-31f21187c74e","executionInfo":{"status":"ok","timestamp":1539616727745,"user_tz":-330,"elapsed":54049,"user":{"displayName":"darshan K S","photoUrl":"","userId":"10064087189825115214"}}},"cell_type":"code","source":["!pip3 install torch torchvision"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting torch\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/49/0e/e382bcf1a6ae8225f50b99cc26effa2d4cc6d66975ccf3fa9590efcbedce/torch-0.4.1-cp36-cp36m-manylinux1_x86_64.whl (519.5MB)\n","\u001b[K    100% |████████████████████████████████| 519.5MB 34kB/s \n","tcmalloc: large alloc 1073750016 bytes == 0x59610000 @  0x7f89d6e632a4 0x594e17 0x626104 0x51190a 0x4f5277 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x510c78 0x5119bd 0x4f5277 0x4f3338 0x510fb0 0x5119bd 0x4f6070 0x4f3338 0x510fb0 0x5119bd 0x4f6070\n","\u001b[?25hCollecting torchvision\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ca/0d/f00b2885711e08bd71242ebe7b96561e6f6d01fdb4b9dcf4d37e2e13c5e1/torchvision-0.2.1-py2.py3-none-any.whl (54kB)\n","\u001b[K    100% |████████████████████████████████| 61kB 18.6MB/s \n","\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.11.0)\n","Collecting pillow>=4.1.1 (from torchvision)\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/62/94/5430ebaa83f91cc7a9f687ff5238e26164a779cca2ef9903232268b0a318/Pillow-5.3.0-cp36-cp36m-manylinux1_x86_64.whl (2.0MB)\n","\u001b[K    100% |████████████████████████████████| 2.0MB 5.2MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from torchvision) (1.14.6)\n","Installing collected packages: torch, pillow, torchvision\n","  Found existing installation: Pillow 4.0.0\n","    Uninstalling Pillow-4.0.0:\n","      Successfully uninstalled Pillow-4.0.0\n","Successfully installed pillow-5.3.0 torch-0.4.1 torchvision-0.2.1\n"],"name":"stdout"}]},{"metadata":{"id":"DCcwMHe9GHxO","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":35},"outputId":"66747464-7fe9-4859-a805-563f4186a4c7","executionInfo":{"status":"ok","timestamp":1539630357994,"user_tz":-330,"elapsed":1064,"user":{"displayName":"darshan K S","photoUrl":"","userId":"10064087189825115214"}}},"cell_type":"code","source":["import torch\n","\n","device = torch.device('cuda') #We need this device argument to place Tensor on GPU\n","print(device)\n","\n","batch_size, in_D, Hid_D, out_D = 64, 1000, 100, 10\n","# in_D - Input Dimension, out_D - Output Dimension, Hid_D - Hidden Dimension\n","\n","\n","# Here we are Initializing Input and Output with Random values, For experimental purposes.\n","x = torch.randn(batch_size,in_D,device=device) # We need to declare the type of Hardware to which Tensors need to be deployed on (CPU/GPU)\n","y = torch.randn(batch_size,out_D,device=device)\n","\n","\n","\n","#Initialize the Hidden Layer's Weights Randomly.\n","\n","#W1 set of weights are initialzed from Input Layer to Hidden Later.\n","w1 = torch.randn(in_D,Hid_D,device=device)\n","#W2 set of weights are initialized from Hidden Layer to Output Layer.\n","w2 = torch.randn(Hid_D,out_D,device=device)\n","\n"],"execution_count":26,"outputs":[{"output_type":"stream","text":["cuda\n"],"name":"stdout"}]},{"metadata":{"id":"j3l5ZpHdJTXr","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":9108},"outputId":"a4e4e588-1054-43df-de72-2f2b7385965a","executionInfo":{"status":"ok","timestamp":1539630361700,"user_tz":-330,"elapsed":3612,"user":{"displayName":"darshan K S","photoUrl":"","userId":"10064087189825115214"}}},"cell_type":"code","source":["# Select a learning rate\n","lr = 0.000002\n","\n","for epoch in range(500):\n","  # Feed Forward\n","  hidden       = x.mm(w1)           # Compute Hidden layer values multiplying x-Input and w1-Weights b/n Input and hidden layer\n","  hid_act_relu = hidden.clamp(min=0) #Apply Relu activation function on the Computed Hidden layer data\n","  y_predict    = hid_act_relu.mm(w2) #predict the Ouput values by multiplying the Hidden layer values with the weights between Hidden Layer and Outpu\n","  \n","#Calculate Loss and store it in a pytorch Tensor\n","  loss = (y_predict - y).pow(2).sum()\n","  print(epoch, loss.item())\n","\n","#Back-Propogation to compute the gradients of w1 and w2 with respect to loss\n","\n","  grad_y_predict = 2.0 * (y_predict - y)\n","  grad_w2 = hid_act_relu.t().mm(grad_y_predict) # We have got Gradient of Weight 2 here.\n","  grad_h_relu = grad_y_predict.mm(w2.t())\n","  grad_h = grad_h_relu.clone()\n","  grad_h[hidden<0] = 0\n","\n","  grad_w1 = x.t().mm(grad_h)\n","\n","  w1 = w1 - lr * grad_w1\n","  w2 = w2 - lr * grad_w2"],"execution_count":27,"outputs":[{"output_type":"stream","text":["0 38087912.0\n","1 187068640.0\n","2 678838720.0\n","3 4978459.0\n","4 1411622.125\n","5 784804.5\n","6 532543.4375\n","7 401168.0625\n","8 316948.3125\n","9 257338.484375\n","10 213599.65625\n","11 180535.765625\n","12 156148.3125\n","13 136506.0625\n","14 120168.6875\n","15 106447.5234375\n","16 94872.1171875\n","17 85044.875\n","18 76583.0390625\n","19 69238.78125\n","20 62803.55078125\n","21 57166.09765625\n","22 52232.05859375\n","23 47858.5625\n","24 43949.15234375\n","25 40456.93359375\n","26 37319.5703125\n","27 34487.4453125\n","28 31940.779296875\n","29 29635.25\n","30 27537.78125\n","31 25627.8515625\n","32 23888.390625\n","33 22297.98046875\n","34 20840.48828125\n","35 19502.384765625\n","36 18273.755859375\n","37 17142.8671875\n","38 16099.69140625\n","39 15139.291015625\n","40 14250.7607421875\n","41 13427.88671875\n","42 12665.1650390625\n","43 11957.0673828125\n","44 11300.44140625\n","45 10690.5068359375\n","46 10121.5048828125\n","47 9590.751953125\n","48 9095.583984375\n","49 8635.0009765625\n","50 8203.904296875\n","51 7800.5908203125\n","52 7422.38037109375\n","53 7068.15869140625\n","54 6737.67138671875\n","55 6425.21435546875\n","56 6131.55615234375\n","57 5855.41796875\n","58 5595.91064453125\n","59 5351.2392578125\n","60 5120.55908203125\n","61 4903.00341796875\n","62 4697.6103515625\n","63 4503.5908203125\n","64 4320.32373046875\n","65 4146.95068359375\n","66 3983.351318359375\n","67 3829.0849609375\n","68 3682.340576171875\n","69 3543.32080078125\n","70 3411.453125\n","71 3286.412841796875\n","72 3167.81005859375\n","73 3055.177734375\n","74 2948.1923828125\n","75 2846.58056640625\n","76 2749.95556640625\n","77 2658.129638671875\n","78 2571.258056640625\n","79 2488.4169921875\n","80 2409.2568359375\n","81 2333.947998046875\n","82 2262.18701171875\n","83 2193.801025390625\n","84 2128.59716796875\n","85 2066.423583984375\n","86 2007.2100830078125\n","87 1950.640625\n","88 1896.6480712890625\n","89 1845.394287109375\n","90 1796.54052734375\n","91 1749.6219482421875\n","92 1704.789306640625\n","93 1661.943359375\n","94 1620.9580078125\n","95 1581.7703857421875\n","96 1544.4268798828125\n","97 1508.8135986328125\n","98 1474.73486328125\n","99 1442.1051025390625\n","100 1411.137939453125\n","101 1381.18310546875\n","102 1352.4984130859375\n","103 1324.96923828125\n","104 1298.6033935546875\n","105 1273.31787109375\n","106 1249.0738525390625\n","107 1225.8397216796875\n","108 1203.548583984375\n","109 1182.1868896484375\n","110 1161.816162109375\n","111 1142.0909423828125\n","112 1123.168212890625\n","113 1105.06884765625\n","114 1087.666748046875\n","115 1070.970458984375\n","116 1054.9268798828125\n","117 1039.514404296875\n","118 1024.7044677734375\n","119 1010.570556640625\n","120 996.92333984375\n","121 983.7554931640625\n","122 971.095947265625\n","123 958.9254760742188\n","124 947.2244262695312\n","125 936.0130004882812\n","126 925.3863525390625\n","127 915.1478271484375\n","128 905.41796875\n","129 895.9679565429688\n","130 886.8526611328125\n","131 878.0689697265625\n","132 869.613525390625\n","133 861.46337890625\n","134 853.6174926757812\n","135 846.0619506835938\n","136 838.804931640625\n","137 831.8323364257812\n","138 825.0689697265625\n","139 818.5457153320312\n","140 812.2613525390625\n","141 806.2000122070312\n","142 800.357177734375\n","143 794.7244262695312\n","144 789.3006591796875\n","145 784.1185302734375\n","146 779.0690307617188\n","147 774.1961059570312\n","148 769.4934692382812\n","149 764.9633178710938\n","150 760.5867919921875\n","151 756.36376953125\n","152 752.3034057617188\n","153 748.4117431640625\n","154 744.6175537109375\n","155 740.9549560546875\n","156 737.4241333007812\n","157 734.016845703125\n","158 730.7797241210938\n","159 727.6539306640625\n","160 724.6605224609375\n","161 721.7550659179688\n","162 718.9396362304688\n","163 716.2186279296875\n","164 713.5907592773438\n","165 711.051025390625\n","166 708.5972900390625\n","167 706.2379150390625\n","168 703.966552734375\n","169 701.753662109375\n","170 699.6122436523438\n","171 697.541748046875\n","172 695.54296875\n","173 693.6124267578125\n","174 691.7506103515625\n","175 689.9647827148438\n","176 688.219482421875\n","177 686.5325317382812\n","178 684.9035034179688\n","179 683.3306884765625\n","180 681.8064575195312\n","181 680.3370361328125\n","182 678.9246215820312\n","183 677.5452880859375\n","184 676.2116088867188\n","185 674.924072265625\n","186 673.6784057617188\n","187 672.471435546875\n","188 671.31103515625\n","189 670.18994140625\n","190 669.0986938476562\n","191 668.0430908203125\n","192 667.0255126953125\n","193 666.038330078125\n","194 665.0825805664062\n","195 664.1696166992188\n","196 663.2940063476562\n","197 662.445068359375\n","198 661.6239624023438\n","199 660.829833984375\n","200 660.0618896484375\n","201 659.321533203125\n","202 658.6053466796875\n","203 657.9053344726562\n","204 657.2274169921875\n","205 656.5715942382812\n","206 655.935791015625\n","207 655.3221435546875\n","208 654.7343139648438\n","209 654.157958984375\n","210 653.5982666015625\n","211 653.0565185546875\n","212 652.531982421875\n","213 652.0241088867188\n","214 651.5377197265625\n","215 651.060546875\n","216 650.5977783203125\n","217 650.1500244140625\n","218 649.7172241210938\n","219 649.2979736328125\n","220 648.89501953125\n","221 648.5009765625\n","222 648.1182250976562\n","223 647.747314453125\n","224 647.3878173828125\n","225 647.0399780273438\n","226 646.7066650390625\n","227 646.3802490234375\n","228 646.0634155273438\n","229 645.7559204101562\n","230 645.4598999023438\n","231 645.1716918945312\n","232 644.8951416015625\n","233 644.6243286132812\n","234 644.3616943359375\n","235 644.10693359375\n","236 643.85986328125\n","237 643.6201782226562\n","238 643.39111328125\n","239 643.1663818359375\n","240 642.9483032226562\n","241 642.7364501953125\n","242 642.5314331054688\n","243 642.3329467773438\n","244 642.1441040039062\n","245 641.9577026367188\n","246 641.7764892578125\n","247 641.6005249023438\n","248 641.4301147460938\n","249 641.2647705078125\n","250 641.107421875\n","251 640.9518432617188\n","252 640.8011474609375\n","253 640.6550903320312\n","254 640.5133666992188\n","255 640.3760986328125\n","256 640.2449340820312\n","257 640.1157836914062\n","258 639.99072265625\n","259 639.8690185546875\n","260 639.751220703125\n","261 639.6370239257812\n","262 639.529052734375\n","263 639.421630859375\n","264 639.3172607421875\n","265 639.2158203125\n","266 639.11767578125\n","267 639.0224609375\n","268 638.9313354492188\n","269 638.841796875\n","270 638.7547607421875\n","271 638.6705932617188\n","272 638.5888061523438\n","273 638.509521484375\n","274 638.4332885742188\n","275 638.3587646484375\n","276 638.2861938476562\n","277 638.2156372070312\n","278 638.1473388671875\n","279 638.0810546875\n","280 638.0171508789062\n","281 637.9552612304688\n","282 637.8947143554688\n","283 637.8358764648438\n","284 637.7787475585938\n","285 637.723388671875\n","286 637.6705322265625\n","287 637.619140625\n","288 637.5684814453125\n","289 637.5193481445312\n","290 637.4714965820312\n","291 637.42529296875\n","292 637.3803100585938\n","293 637.3370361328125\n","294 637.2951049804688\n","295 637.2540893554688\n","296 637.2141723632812\n","297 637.17529296875\n","298 637.1376953125\n","299 637.1011352539062\n","300 637.0659790039062\n","301 637.0319213867188\n","302 636.99853515625\n","303 636.9660034179688\n","304 636.9346313476562\n","305 636.9039916992188\n","306 636.8743286132812\n","307 636.8456420898438\n","308 636.8179321289062\n","309 636.7908325195312\n","310 636.7643432617188\n","311 636.7386474609375\n","312 636.7139282226562\n","313 636.689697265625\n","314 636.6661376953125\n","315 636.6438598632812\n","316 636.6217651367188\n","317 636.6001586914062\n","318 636.579345703125\n","319 636.5590209960938\n","320 636.539306640625\n","321 636.5200805664062\n","322 636.5020141601562\n","323 636.484375\n","324 636.4668579101562\n","325 636.4496459960938\n","326 636.4330444335938\n","327 636.4170532226562\n","328 636.4013061523438\n","329 636.3861083984375\n","330 636.3714599609375\n","331 636.3573608398438\n","332 636.3434448242188\n","333 636.3298950195312\n","334 636.3165893554688\n","335 636.3148803710938\n","336 636.3135375976562\n","337 636.312255859375\n","338 636.3109741210938\n","339 636.3098754882812\n","340 636.30859375\n","341 636.3074340820312\n","342 636.3064575195312\n","343 636.3052978515625\n","344 636.3042602539062\n","345 636.3031616210938\n","346 636.3021240234375\n","347 636.3011474609375\n","348 636.3001098632812\n","349 636.2991943359375\n","350 636.2982788085938\n","351 636.2974853515625\n","352 636.2965698242188\n","353 636.2957153320312\n","354 636.2947998046875\n","355 636.2939453125\n","356 636.2930908203125\n","357 636.2922973632812\n","358 636.2915649414062\n","359 636.2907104492188\n","360 636.2899169921875\n","361 636.2891235351562\n","362 636.28857421875\n","363 636.2877807617188\n","364 636.2869262695312\n","365 636.2863159179688\n","366 636.28564453125\n","367 636.2849731445312\n","368 636.2843627929688\n","369 636.2838134765625\n","370 636.2830810546875\n","371 636.2822875976562\n","372 636.2817993164062\n","373 636.2810668945312\n","374 636.280517578125\n","375 636.2799072265625\n","376 636.2792358398438\n","377 636.2786254882812\n","378 636.2781372070312\n","379 636.2775268554688\n","380 636.2770385742188\n","381 636.2764282226562\n","382 636.2758178710938\n","383 636.2752075195312\n","384 636.2747802734375\n","385 636.274169921875\n","386 636.2735595703125\n","387 636.2730102539062\n","388 636.2724609375\n","389 636.27197265625\n","390 636.2715454101562\n","391 636.2709350585938\n","392 636.2704467773438\n","393 636.2698974609375\n","394 636.2694091796875\n","395 636.2689819335938\n","396 636.2684326171875\n","397 636.2678833007812\n","398 636.267333984375\n","399 636.2669067382812\n","400 636.266357421875\n","401 636.265869140625\n","402 636.265380859375\n","403 636.2649536132812\n","404 636.2644653320312\n","405 636.2640380859375\n","406 636.2635498046875\n","407 636.2630615234375\n","408 636.262451171875\n","409 636.2620849609375\n","410 636.26171875\n","411 636.26123046875\n","412 636.2606811523438\n","413 636.26025390625\n","414 636.259765625\n","415 636.2593383789062\n","416 636.2589111328125\n","417 636.2584838867188\n","418 636.2581176757812\n","419 636.2575073242188\n","420 636.2570190429688\n","421 636.256591796875\n","422 636.256103515625\n","423 636.2557373046875\n","424 636.2551879882812\n","425 636.2548217773438\n","426 636.2542724609375\n","427 636.2538452148438\n","428 636.2534790039062\n","429 636.2530517578125\n","430 636.2525634765625\n","431 636.252197265625\n","432 636.2516479492188\n","433 636.2513427734375\n","434 636.2509155273438\n","435 636.2503662109375\n","436 636.25\n","437 636.24951171875\n","438 636.2490844726562\n","439 636.2486572265625\n","440 636.2481079101562\n","441 636.247802734375\n","442 636.2472534179688\n","443 636.246826171875\n","444 636.2464599609375\n","445 636.2460327148438\n","446 636.2455444335938\n","447 636.2453002929688\n","448 636.2446899414062\n","449 636.2442626953125\n","450 636.243896484375\n","451 636.2435913085938\n","452 636.2429809570312\n","453 636.2426147460938\n","454 636.2420043945312\n","455 636.2418212890625\n","456 636.2412719726562\n","457 636.240966796875\n","458 636.2405395507812\n","459 636.2399291992188\n","460 636.2396240234375\n","461 636.2392578125\n","462 636.2388305664062\n","463 636.2383422851562\n","464 636.2379150390625\n","465 636.237548828125\n","466 636.2371215820312\n","467 636.2366333007812\n","468 636.2362670898438\n","469 636.23583984375\n","470 636.2355346679688\n","471 636.2349853515625\n","472 636.2344970703125\n","473 636.2340698242188\n","474 636.233642578125\n","475 636.2332153320312\n","476 636.2327880859375\n","477 636.2323608398438\n","478 636.2319946289062\n","479 636.2315063476562\n","480 636.2310791015625\n","481 636.2306518554688\n","482 636.2302856445312\n","483 636.2299194335938\n","484 636.2294311523438\n","485 636.2289428710938\n","486 636.228515625\n","487 636.2282104492188\n","488 636.227783203125\n","489 636.2273559570312\n","490 636.2269287109375\n","491 636.2264404296875\n","492 636.2261352539062\n","493 636.2255859375\n","494 636.2252807617188\n","495 636.2247314453125\n","496 636.2244262695312\n","497 636.2240600585938\n","498 636.2235107421875\n","499 636.2230834960938\n"],"name":"stdout"}]},{"metadata":{"id":"MCVoJwyoc1g2","colab_type":"code","colab":{}},"cell_type":"code","source":[""],"execution_count":0,"outputs":[]}]}